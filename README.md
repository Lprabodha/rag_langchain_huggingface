# RAG Application with LangChain and Hugging Face LLM
ðŸš€ Retrieval-Augmented Generation (RAG) for Document Q&A using LangChain and Hugging Face LLMs

## Overview
This repository contains a RAG-based application that uses LangChain, Hugging Face's Zephyr-7B LLM, and ChromaDB to answer questions based on document content. The application processes PDF documents, extracts relevant text chunks, stores them in a vector database, and retrieves context-aware answers.

Features

- âœ… Load PDF documents for text-based Q&A.
- âœ… Use LangChain for LLM integration with Hugging Face models.
- âœ… Generate embeddings using sentence-transformers.
- âœ… Store and retrieve document chunks using ChromaDB.
- âœ… Chain prompts for better contextual responses.
- âœ… Automated Q&A over AWS networking concepts (e.g., VPC, AWS Fargate).